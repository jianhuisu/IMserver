# 一致性hash算法

那么什么是hash算法呢，百度百科的定义如下：

>哈希算法将任意长度的二进制值映射为较短的固定长度的二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。

### 普通的hash算法在分布式应用中的不足：

比如，在分布式的存储系统中，要将数据存储到具体的节点上，如果我们采用普通的hash算法进行路由，将数据映射到具体的节点上，如key%N，key是数据的key，N是机器节点数，
如果有一个机器加入或退出这个集群，则所有的数据映射都无效了，

- 如果是持久化存储则要做数据迁移， mysql 
- 如果是分布式缓存，则其他缓存就失效了。 redis 

	$data = DB::select(*)->from('user')->all();
	$redis->set('user_list',$data,3600);

	$instanceIndex = to_num(user_list) / ser_num.


一个服务节点因为故障退出  将导致所有缓存集体失效.需要重新生成.

### 一致性hash算法较普通hash算法的优势


按照常用的hash算法来将对应的key哈希到一个具有2^32次方个节点的空间中，即0 ~ (2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。

	struct node {
		int srv_node_addr;  // 将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或唯一主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。
		int node_index_num; 
		node * next;
	}

	map: 
		node1
		node2
		node3
		node4
		node1


1. 首先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
2. 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
3. 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。

余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在园（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响.


### 应用实例

1 删除节点

环上一共5个srv. 

	key_A1 => srvA1
	key_A2 => srvA2
	key_A3 => srvA3
	key_A4 => srvA4
	key_A5 => srvA5
	key_A1 => srvA1

srvA4因为故障退出. srv在环上的分布

环上一共4个srv. 

	key_A1 => srvA1
	key_A2 => srvA2
	key_A3 => srvA3
	key_A4 => NULL
	key_A5 => srvA5
	key_A1 => srvA1

演变为 

	key_A1 => srvA1
	key_A2 => srvA2
	key_A3 => srvA3
	key_A4,key_A5 => srvA5
	key_A1 => srvA1

也就是说 只有原来srvA4上的缓存失效,需要重新生成 并迁移到srvA5节点上. 而其它节点的缓存数据不受影响.
相较于普通的hash算法.一个节点故障可能导致整个所有节点的缓存都需要重新生成,极大的缩小的影响范围.
(所以 我们在设置redis_key时 尽量使用 key_name:key_id的顺序而不是反过来. 尽量将同一个业务的的key映射到同一个节点上)


增加节点:增加一个srvA6.

现在srvA5与srvA1之间新增一个服务节点.目的是用来分担之前srvA1节点的压力. 这样原来打到srvA1上的部分key中的一部分会迁移到srvA6节点上.
如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。

综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。
此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：

`同时数据定位算法不变`，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。


 - 容错性 : 将错误限制在局部 不会影响全局
 - 扩展性 :  方便调整 

### 参考资料

https://www.cnblogs.com/lpfuture/p/5796398.html








