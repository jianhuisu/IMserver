## 分布式_业务补偿


本地事务,同时操作多个表时.有很大的缺陷，因为开启事务一般是锁表的，事务执行期间会一直锁着，其他的操作一般都要排队等待，对性能要求比较高的系统是不能忍受的。

特别是涉及改动不同数据库的操作，这会造成跨库事务，性能更加低
如果还涉及到不在同一台服务器、甚至不同网段部署的数据库，那本地事务简直是系统运行的灾难，是首先需要丢弃的解决方案。

**如果有海量数据需要处理、或者要求高并发请求的话，同步的事务机制已经是不现实的了，这种情况下必须采用异步事务机制，既`分段式的事务`**
分段式事务一般做法就是把需求任务分段式地完成，通过事务补偿机制来保证业务最终执行成功，补偿机制一般可以归类为2种：

#### 定时任务补偿

通过定时任务去跟进后续任务，根据不同的状态表确定下一步的操作，从而保证业务最终执行成功，这种办法可能会涉及到很多的后台服务，维护起来也会比较麻烦，这是应该是早期比较流行的做法

#### 消息补偿

通过消息中间件触发下一段任务，既通过实时消息通知下一段任务开始执行，执行完毕后的消息回发通知来保证业务最终完成；
当然这也是异步进行的，但是能保证数据最终的完整性、一致性，也是.近几年比较热门的做法.

所以目前最流行的分布式事务实现方案为:使用事务补偿机制

 1. MQ发送方`投递`远程事务消息到MQ Server;
 2. MQ Server给予响应, 表明事务消息已成功到达MQ Server.(使用回执来确定)
 3. MQ发送方Commit本地事务.
 4. 若本地事务Commit成功, 则通知MQ Server允许对应事务消息被消费; 若本地事务失败, 则通知MQ Server对应事务消息应被丢弃.
 5. 若MQ发送方超时未对MQ Server作出本地事务执行状态的反馈, 那么需要MQ Servfer向MQ发送方主动回查事务状态, 以决定事务消息是否能被消费.（todo ？）
 6. 当得知本地事务执行成功时, MQ Server允许MQ订阅方消费本条事务消息.

 之前写服务的时候没有用2-pc，用的还是异步消息的事务补偿机制，但没有上面的这么复杂，首先 A->B, A→C结合一些A的本地DB操作被包裹进大的事务里，若C调用失败触发回滚，在捕获C调用失败的异常时往kafka写入消息通知给B回滚，A不会直接调用B的接口去手动回滚因为这个动作耗时且可能失败，而送入kafka让B的消费者线程来消费可以保证多次重试以及日志准确记录。

 ### 参考资料 

 https://www.cnblogs.com/h-c-g/p/11210226.html