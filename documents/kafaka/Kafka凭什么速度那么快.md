# Kafka凭什么速度那么快

 - 顺序写入
 - Memory Mapped Files
 - zero copy 
 
## 顺序写入

磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。在顺序读写的情况下，磁盘的顺序读写速度和内存持平。
因为硬盘是机械结构，每次读写都会寻址->写入，其中寻址是一个“机械动作”，它是最耗时的。
以硬盘最讨厌随机I/O，最喜欢顺序I/O。为了提高读写硬盘的速度，Kafka就是使用顺序I/O。

 - 磁盘顺序读写速度超过内存随机读写
 - 系统冷启动后，磁盘缓存依然可用
 
kafka有一个缺陷——没有办法删除数据 ，所以Kafka是不会删除数据的，它会把所有的数据都保留下来，
每个消费者（Consumer）对每个Topic都有一个offset用来表示读取到了第几条数据 。

如果不删除硬盘肯定会被撑满，所以Kakfa提供了两种策略来删除数据：

 - 一是基于时间；
 - 二是基于partition文件大小。

## Memory Mapped Files

即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并不是实时的写入硬盘 ，它充分利用了现代操作系统分页存储来利用内存提高I/O效率。

Memory Mapped Files(后面简称mmap)也被翻译成 内存映射文件 ，在64位操作系统中一般可以表示20G的数据文件，
它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。
完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。
通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底。

使用这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。）

## read data: 基于sendfile实现Zero Copy

传统模式下，当需要对一个文件进行传输的时候，其具体流程细节如下：

 1. 调用read函数，文件数据`from disk to`内核缓冲区
 2. read函数返回，文件数据从内核缓冲区copy到用户缓冲区
 1. write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区
 1. 数据从socket缓冲区copy到相关协议引擎

以上细节是传统read/write方式进行网络文件传输的方式，我们可以看到，在这个过程当中，文件数据实际上是经过了`四次`copy操作：

    硬盘 —> 内核buf —> 用户buf —> socket相关缓冲区 —> 协议引擎

而sendfile系统调用则提供了一种减少以上多次copy，提升文件传输性能的方法。
在内核版本2.1中，引入了sendfile系统调用，以简化网络上和两个本地文件之间的数据传输。
sendfile的引入不仅减少了数据复制，还减少了上下文切换。

    sendfile(socket, file, len);

运行流程如下：

 1. sendfile系统调用，文件数据被copy至内核缓冲区
 1. 再从内核缓冲区copy至内核中socket相关的缓冲区 (not need through user buf)
 1. 最后再socket相关的缓冲区copy到协议引擎

>todo : if user need modify file contents , how to do ?
>请教一下 zero copy 时如果用户需要对文件内容修改如何处理？是因为kafka的应用场景从本身避免了修改需求 所以才可以采用 copy策略吗？

相较传统read/write方式，2.1版本内核引进的sendfile已经减少了内核缓冲区到user缓冲区，
再由user缓冲区到socket相关缓冲区的文件copy，而在内核版本2.4之后，
文件描述符结果被改变，sendfile实现了更简单的方式，再次减少了一次copy操作。

在Apache、Nginx、lighttpd等web服务器当中，都有一项sendfile相关的配置，使用sendfile可以大幅提升文件传输性能。

Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把文件发送给消费者，配合mmap作为文件读写方式，直接把它传给sendfile。