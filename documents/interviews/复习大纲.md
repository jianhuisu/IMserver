只有简单的例子才能让你把精力充分集中在算法背后的通用思想和技巧上，而不会被那些隐晦的细节问题搞的莫名其妙

如何做系统优化 ，首先 你需要量化问题 ，如果你无法量化 问题 ，你就无法解决问题

1 监控系统
2 提取指标
3 压力测试
4 分析问题


我们学计算机当程序员最大的福气不是可以到大公司里加班和 996，而是我们生活在了第三次工业革命的信息化时代，这才是最大的福气，
所以，我们应该努力地提升自己，而不是把自己当劳动力一样的卖了！在这样的一个时代，你要做的不是通过加班和拼命来跪着挣钱，而是通过技能来躺着挣钱…

作者：msup
链接：https://zhuanlan.zhihu.com/p/63694008
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

todo mysql optimize https://zhuanlan.zhihu.com/p/65203585


JD （职位描述((Job Description)）
高层看的数据

    第一个特点是大数据平台整个的用户复杂度，不止是数据的同学和技术的同学在使用，还会包括一些BI同学，测试同学，甚至产品运营都可能去使用这个大数据的平台。
    
    第二个特点就是业务复杂，优酷是一个视频网站，它有非常复杂的业务场景，从日志分类上，除了像页面浏览，还会有一些播放相关的数据、性能相关的数据。从整个的业务模式上，有直播、有会员、有广告、有大屏等这样一些非常不一样的场景。
    
    第三个特点，就是数据量非常巨大，一天的日志量会达到千亿级别，这是一个非常庞大的数据量，而且会做非常复杂的计算。
    
    第四个比较有意思，不管是小公司、大公司，对成本的意识是非常高的。优酷也是有非常严格的预算，包括在阿里集团内是有非常严格的预算系统的，但是我们也经常会去做一些重要的战役，像双十一战役，像我们暑期的世界杯战役，还有春节也会搞各种战役。这其实对计算资源的弹性要求是非常高的。

夜里的作业很多

面试说项目经验环节，感觉自己工作经历的项目都很low，故表述时毫无底气还吞吞吐吐，怎么破？

业务复杂度和用户并发量总有一个占优势吧？

为什么选它，项目中如何应用，最后无一例外，它底层是如何实现？怎么保证的稳定的消费者生产者队列？

3、你的简历，就是复习大纲总有人拿网上找到的拿了bat offer的人提供的复习大纲复习，
结果发现并没啥卵用。我这次字节的面试，他提出的所有的问题全部是基于我简历中的技能清单。
我认为很多人但凡能做到简历中技能清单描述的样子，就已经算了不起了。
如果简历中感觉无料可写？我推荐一个好办法：

听说过名字，就写了解；
跟着帖子写过demo，就写熟悉；
项目当中用过，就写熟练掌握；
项目当中经常用，就写精通；


**一定要说实话** 
    包括上一家薪资
    拿到了多少offer
    离职原因
    不要舔 因为舔没用
    别把鸡蛋放到一个篮子
    降低薪资标准

性能和成本之间找到一个良好的平衡点    
    
每天写一遍排序算法
每天手绘一遍三次握手 四次挥手状态图 ,socket函数与状态的对应关系.
手写报文
每天过一遍自己总结的面试题 以及简历的技能请单，背诵自我介绍
向infoQ 投稿


不要说的太流利，适当停顿，边思考边说，否则给人一种背诵的感觉.
回答时技术提问时 避免回答过于单一的问题，挑关键点说.但是也要点到即止
 不露痕迹地说出面试官爱听的话 
 
回答问题时 首先给出结论,然后给出这个结论的理由

面试的通过大部分来自于 总是奢望能力之外的事情. 

#### php源码

swoole 是一个高性能 的网络通信引擎 和 一个高性能的协程框架 使 PHP 不再局限于传统的 Web 领域

值传递与引用传递有什么区别

 - 值传递是将实参的值赋值给形参,形参与实参虽然值相同,但是两个变量指向的内存单元是不同的.两者互不影响.
 - 引用传递是时,实际传递的是 对象的地址,此时形参与实参指向的是同一块存储单元.修改一个就会引发另外一个的改变.

数组+和array_merge的区别 

    当下标为数值时，
    
        array_merge()  索引冲突时 不会覆盖掉原来的值，岔开合并
        但array＋array  索引冲突时 取前者

    当下标为字符时
    
        array_merge()   键名冲突时 取后者
        array＋array()   键名冲突时 取前者 

php7与php5的区别

    1. zval结构体字段的改变,一个zval的占用空间下降到16字节.
    1.  php5中引用计数发生在zval上,php7中引用计数发生在`zval_value`上. zval_value 包括 zend_string zend_array zend_object ...
    
    1. hashtable 整块的数组元素和hash映射表全部连接在一起，被分配在同一块内存内,避免了CPU的缓存命中率下降问题，
       而php5中的bucket存储,并不是在内存中连续分配,而是分散在各个不同的内存区域.
       
       PHP5的Hashtable对于每一个Bucket都是分开申请释放的,而存储在Hashtable中的数据是也会通过pListNext指针串成一个list，可以直接遍历
    
    1. zval的类型做了比较大的调整, 扩充拆分到17种类型:
    1. 增加了AST
        1、Lexing：词法扫描分析，将源文件转换成 token 流；
        2、Parsing：语法分析，在此阶段生成 op arrays。
        3、PHP7 中在语法分析阶段不再直接生成 op arrays，而是先生成 AST，所以过程多了一步：


需要别人的帮助 可能不是在一个下雨天 没必要很特殊 但是我心情应该很不好 或是很迷茫 或是很烦躁 所念皆星河 

解释语言与编译语言区别

    c编译生成的是机器码,目标语言直接在物理机上执行,php在的目标语言在虚拟机上执行
    php编译生成的是opcodes ，在虚拟机上执行,不能直接在物理机上执行
    opcodes物理机不识别, opcodes由虚拟机识别执行
    
变量的垃圾回收 变量自动回收 -> 循环引用 垃圾查看buffer. （对象 与 数组 ）对子成员减去引用 ，查看自身的 引用计数是否为 0

    在php中 普通变量通过引用计数机制，可以实现自动回收，
    但是对于数组 与 对象 两种类型，如果在内部引用了自身，这就会发生循环引用，导致zval可能成为一个垃圾无法释放 ，从而产生垃圾。
    这个时候 内核会将zval统一收集到一个缓冲区中->双向链表，当缓冲区满,对里面的zval进行遍历，尝试对zval的成员进行引用计数减-操作.
    如果发现变量本身的引用计数变为0，那么就证明发生了循环引用，可以释放.
    
php的优化  开启opcache  使用新的编译器
从浏览器输入域名到展示页面都发生了什么

php7的新特性 新的操作符号 ?? <=>/类型声明/命名空间批量倒入/intdiv()/  

    php5.6 之前无法使用 try catch 接口捕获错误，只能捕获异常,
    php7   之后可以使用 try catch 捕获错误，    这样可以预防进程直接退出.
    
常用设计模式  观察者模式  yii2.0 事件驱动的实现 实质为发布订阅模式 / 装饰器模式 动态添加成员属性 组合优于继承 / 策略模式 相同上下文 替换 中间的算法  / 
适配器模式 兼容性，有现成的类型可以用，部分有冲突，使用时配器进行转换， / 单例子模式

    GET请求在URL中传送的参数是有长度限制的，而POST没有。
    对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
    GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
    GET参数通过URL传递，POST放在Request body中。

swoole 是什么 ， swoole 是一个用C编写的php的扩展， 弥补php在多进程/协程/异步通信方面的不足

#### MySQL面试题列表

B+树的高度 假设当前数据表的数据为N，每个磁盘块的数据项的数量是m  H = log以M+1为低 N的对数  

todo mysql事务的底层实现 MVCC ,

如果表都满了，如何进行下一步处理  https://www.cnblogs.com/myseries/p/10930910.html

**叶节点包含了完整的数据记录。这种索引叫做聚集索引**。
Innodb为什么需要主键索引 ，innodb是聚促索引，需要
 
MySQL常见的存储引擎InnoDB、MyISAM的区别？

    1）事务：MyISAM不支持，InnoDB支持
    2）锁级别： MyISAM 表级锁，InnoDB 行级锁
    
    3）MyISAM存储表的总行数；InnoDB不存储总行数；
    4）MyISAM 与 Innodb都采用B+树索引结构，但是innodb的数据与索引是存储在一起的，MyISAM的数据与索引是分离的.
        - MyISAM的叶子结点存储的是指向数据的索引
        - Innodb的叶子结点存储的是实际数据.
    5）
        Innodb是聚促索引，MyISAM不是聚促索引
        InnoDB的辅助索引data域存储相应记录主键的值而不是地址。所以这会比MyISAM多出一次额外的回表操作.    
        
    5）适用场景：
    MyISAM适合： 读多写少 没有事务。
    InnoDB适合： 要求事务； 表更新和查询都相当的频繁
    
回表
前置处理方式

Mysql索引为什么用B+树而不用B-树 

    1 B-结点中含有data域 ，B+只有叶子结点才有data域 
    2 B+叶子结点有序，支持范围查询
    
mysql最左前缀匹配
mysql 优化的步骤
    
    1. 表的设计阶段优化，预估我们的数据量
    2. 维护阶段优化     根据实际业务 调整索引  慢查询日志 ，借助工具分析 
    根据成本 -》 sql语句优化 -》 缓存/中间表/读写分离  -》 分表 垂直分割>水平分割（discuz 帖子分表  id+title 一个表，实际内容 hash取模）
    sql优化 操作性最方便，敏捷性更高
    mysql中有全同步复制机制、半同步复制、异步复制三种复制方案使用全同步复制机制

事务四大特性 ACID
事务的四种隔离级别.MVCC
    
        读未提交   脏读 读到事务过程中的垃圾数据（事务发生会滚，数据消失）
        读已提交   避免脏读 ，但是会存在不可重复读现象 两个同时开始的事务,A开始时读的值与第二次读的值不一致，这是因为事务B提交了对该值的修改.
        可重复读   避免了 不可重复读，MVCC 事务ID。
        串行化

分布式 CAP   强一致性，最终一致性. CP AP 没有 CA  
分布式事务 -> 我们平时都是使用redis来保障分布式事务锁
tidb的金融级别可用是指`CP without A`, 
 
TiDB 处理用户请求的主要流程 首先，请求从 Client 端进来后进入语法解析层，然后对语句进行合法性验证和类型推导，接着做查询优化——这里我们分了逻辑优化和物理优化。

大表如何快速统计出分页信息

    1 利用覆盖索引的思想
    2 保存id 减少 offset 偏移计算
    
分库分表之后，id主键如何处理？
千万级别的大表应该如何优化
大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？
读写分离如何实现
MySQL数据库cpu飙升到500%的话他怎么处理？
有用到中间件么？他们的原理知道么？-》 redis
分库分表了是怎么做的？分表分库了有什么问题？ 分片/部署/运维/数据聚合

#### nginx 

 - `Apache`是同步多进程模型，一个连接对应一个进程. 
 - `Nginx`是**异步非阻塞事件驱动**，

swoole nginx 采用IO模型是效率提升的关键  多路复用+事件驱动

 - `阻塞I/O`    从发起系统调用开始,阻塞进程直到数据拷贝完成 
 - `非阻塞I/O`  进程反复调用IO函数(自身进程反复轮询内核),可以立刻通过函数的返回值知道数据是否就绪.第一阶段不阻塞.如果数据准备就绪,内核进行数据拷贝阶段进程是阻塞.
 - `多路I/O复用`    进程不直接发起系统调用`recvfrom`,改为发起系统调用`select`或者`poll`或者`epoll（Linux 2.6+）`.
    将想要监听的`IO FILE * hanlder`注册到监听队列中,`select`或者`poll`通过轮询的方式监活跃的`IO`.然后通知对应进程.不需要`fork`和多进程就可以实现并发服务的`server`。
    这里的多路指的是`多个网络链接`,复用指的是复用(就是轮流使用)同一个线程.
 - `信号驱动I/O` 首先我们允许`Socket`进行信号驱动`IO`,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个`SIGIO`信号，可以在信号处理函数中调用`I/O`操作函数处理数据。
    有时也称此方式为异步I/O。但是严格讲，该方式并不能算真正的异步I/O，因为实际读取数据到应用进程缓存的工作仍然是由应用自己负责的。  
 - `异步I/O` `AIO`   异步IO不是顺序执行(主要依靠回调执行).用户进程进行`aio_read`系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。**IO两个阶段，进程都是非阻塞的**。
    **事件驱动是异步的实现方式，而回调函数是事件驱动的实现方式**

nginx 

 - nginx 异步非阻塞事件驱动模型 
 - apache 同步阻塞多进程模型

    1. round robin
    2. weight
    3. IP_hash
    4. url_hash
    5. fair 使用第三方
    
    
线程同步 三种方式
    
    临界区
    信号量
    事件通知    

#### redis


秒杀系统的实现 redis分slot，时一个slot用完了，怎么办 
    
    秒杀活动有几个特点 
        1 瞬时流量高
        2 读多写少
        3 核心操作简单 -> 减库存
        
    针对这三个问题，对应的处理措施为 
    
        1 使用MQ来进行流量削峰                  
        2 读多写少 将库存量缓存到 redis里面
        3 异步处理下单

接口安全

    传输过程
    客户端js        


如何解决超卖问题 使用redis的计数器 判断库存减一以后是否 `> -1` ，大于则可以 ，否则结束
redis hashtable的扩张与收缩 渐进式hash 负载因子小于0.1 时进行收缩
redis为什么这么快 内存 多路复用非阻塞IO 单线程 VM机制 减少系统调用

多个命令在并发中也是原子性的吗？ 不一定， 将get和set改成单命令操作，incr 。使用Redis的事务，或者使用Redis+Lua==的方式实现.

select / poll / epoll 是多路复用的三种实现区别与联系 epoll没有最大连接数限制,只扫描活跃的连接

redis的使用场景？  计数器/存储对象 hash /消息队列/锁
redis的数据持久化方式 AOF RDB `fork 使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能`
redis的过期键删除策略    定时删除 惰性删除 定期删除
redis的数据淘汰策略，内存不足时，淘汰一些数据 6种 noeviction allkeys-lru allkeys-random volatile-lru volatile-random volatile-ttl
redis内存用完会发生什么 （拒绝服务可读不可写/淘汰数据）
MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据 ，选择合适的数据淘汰策略。
redis如何保障操作的原子性
缓存穿透（绕过去）/缓存雪崩/缓存击穿（对点高速攻击）   缓存预热
redis的事务 redis的事务不支持会滚

Memcache与Redis的区别都有哪些？

    1 redis 持久化 memcache断电丢失
    2 memcache 数据类型单一 只支持 字符串类型，redis  【string  set zset list hash】
    3 redis string 最大512M memcache 1G

redis 的数据类型 回答：一共五种；底层简单字符串等.

    (一)String
    这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。
    
    set/get => setnx
    
    两个命令分离调用，中间容易插入其它客户端的请求. 
    if(!get(key)){
        set(key)
    }
    推荐 setnx
    
    setnx lock.key value1
    success: return 1
    fail   : return 0;
    
    解锁：使用 del key 命令就能释放锁
    
    解决死锁：
    1）通过Redis中expire()给锁设定最大持有时间，如果超过，则Redis来帮我们释放锁。
    2）使用 setnx key “当前系统时间+锁持有的时间”和getset key “当前系统时间+锁持有的时间”组合的命令就可以实现。
    
    SETNX 命令
    setnx key value
    
    设置指定 key 的值为 value，只有在 key 不存在时设置 key 的值。
    setnx（SET if Not eXists） 命令在指定的 key 不存在时，为 key 设置指定的值。
    设置成功，返回 1 。 设置失败，返回 0 。
    
    GETSET 命令
    getset key value
    设置指定 key 的值为 value，并返回 key 的旧值(old value)。
    返回给定 key 的旧值。 当 key 没有旧值时，即 key 不存在时，返回 nil 。
    当 key 存在但不是字符串类型时，返回一个错误。
    
    
    (二)hash
    这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。
    
    (三)list
    使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。
    本人还用一个场景，很合适—取行情信息。就也是个生产者和消费者的场景。LIST可以很好的完成排队，先进先出的原则。
    
    (四)set 集合
    因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？
    因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。
    另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
    
    (五)sorted set  有序集合
    sorted set多了一个权重参数score,集合中的元素能够按score进行排序。可以做排行榜应用，取TOP N操作。

redis 的内部数据结构
    
    dict 本质上是为了解决算法中的查找问题（Searching）是一个用于维护key和value映射关系的数据结构，与很多语言中的Map或dictionary类似。 本质上是为了解决算法中的查找问题（Searching）
    sds sds就等同于char * 它可以存储任意二进制数据，不能像C语言字符串那样以字符’\0’来标识字符串的结 束，因此它必然有个长度字段。
    skiplist （跳跃表） 跳表是一种实现起来很简单，单层多指针的链表，它查找效率很高，堪比优化过的二叉平衡树，且比平衡树的实现，
    quicklist
    ziplist 压缩表 这个不太熟悉

redis 线程工作模型

Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问

    1)I/O 多路复用程序负责监听多个套接字， 并向文件事件分派器传送那些产生了事件的套接字。
        尽管多个文件事件可能会并发地出现， 但 I/O 多路复用程序总是会将所有产生事件的套接字都入队到一个队列里面，
         
    2） 然后通过这个队列， 以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字：
       当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， 
       I/O 多路复用程序才会继续向文件事件分派器传送下一个套接字。如果一个套接字又可读又可写的话， 那么服务器将先读套接字， 后写套接字.

redis事务不保证原子性，所以用的比较少 ，只了解发生错误时不会滚.   
    
    
#### tcp/ip 协议

1 TCP是面向连接的传输控制协议 UDP提供无连接的数据包服务
2 TCP是可靠的数据传输协议  UDP不可考
3 TCP占用的系统资源比较多,UDP比较少.
4 UDP的实时性TCP高.

为三次   这是为了防止已经失效的 `请求连接报文` 突然被传送到服务端。占用资源
为四次   1 确保 2msl 时间内 last_ack 可以发送到服务端   2  防止失效连接报文突然 到达

#### 三剑客


根据nginx访问日志 统计 QPS

    非实时 cat access.log | awk -F '[' '{print $2}' | awk -F ']' '{print $1}' | sort | uniq -c | sort -nr
    实时   tail -f | awk -F '[' '{print $2}' | awk -F ']' '{print $1}' | sort | uniq -c | sort -nr
    














